\c regression
SELECT datname, node_seq_id
FROM bdr.bdr_nodes
INNER JOIN pg_database ON (node_dboid = pg_database.oid);
  datname   | node_seq_id 
------------+-------------
 postgres   |           1
 regression |           2
(2 rows)

SELECT bdr.bdr_replicate_ddl_command($DDL$
CREATE SEQUENCE public.dummy_seq;
$DDL$);
 bdr_replicate_ddl_command 
---------------------------
 
(1 row)

-- Generate enough values to wrap around the sequence bits twice.
-- If a machine can generate 16k sequence values per second it could
-- wrap. Force materialization to a tuplestore so we don't slow down
-- generation.
--
-- We should get no duplicates.
WITH vals(val) AS (
   SELECT bdr.global_seq_nextval('dummy_seq'::regclass)
   FROM generate_series(1, (2 ^ 14)::bigint * 2)
   OFFSET 0
)
SELECT val, 'duplicate'
FROM vals
GROUP BY val
HAVING count(val) > 1
UNION ALL
SELECT count(distinct VAL), 'ndistinct'
FROM vals;
  val  | ?column?  
-------+-----------
 32768 | ndistinct
(1 row)

SELECT bdr.bdr_replicate_ddl_command($DDL$
CREATE SEQUENCE public.dummy_seq2;
$DDL$);
 bdr_replicate_ddl_command 
---------------------------
 
(1 row)

SELECT bdr.bdr_replicate_ddl_command($DDL$
CREATE TABLE public.seqvalues (id bigint);
$DDL$);
 bdr_replicate_ddl_command 
---------------------------
 
(1 row)

SELECT node_seq_id FROM bdr.bdr_nodes
WHERE (node_sysid, node_timeline, node_dboid) = bdr.bdr_get_local_nodeid();
 node_seq_id 
-------------
           2
(1 row)

-- Generate enough sequences to almost wrap by forcing
-- the same timestamp to be re-used.
INSERT INTO seqvalues(id)
SELECT bdr.global_seq_nextval_test('dummy_seq2'::regclass, '530605914245317'::bigint)
FROM generate_series(0, (2 ^ 14)::bigint - 2);
SELECT bdr.bdr_replicate_ddl_command($DDL$
CREATE UNIQUE INDEX ON public.seqvalues(id);
$DDL$);
 bdr_replicate_ddl_command 
---------------------------
 
(1 row)

-- This should wrap around and fail. Since we're always running on the same
-- node with the same nodeid, and starting at the same initial sequence value,
-- it'll do so at the same value too.
INSERT INTO seqvalues(id)
SELECT bdr.global_seq_nextval_test('dummy_seq2'::regclass, '530605914245317'::bigint);
ERROR:  duplicate key value violates unique constraint "seqvalues_id_idx"
DETAIL:  Key (id)=(25074801076895745) already exists.
-- So we'll see the same stop-point
SELECT last_value FROM dummy_seq2;
 last_value 
------------
      16384
(1 row)

SELECT bdr.wait_slot_confirm_lsn(NULL,NULL);
 wait_slot_confirm_lsn 
-----------------------
 
(1 row)

\c postgres
-- We should be able to insert the same number of values on the other node
-- before wrapping, even if we're using the same timestamp-part.
SELECT node_seq_id FROM bdr.bdr_nodes
WHERE (node_sysid, node_timeline, node_dboid) = bdr.bdr_get_local_nodeid();
 node_seq_id 
-------------
           1
(1 row)

SELECT last_value FROM dummy_seq2;
 last_value 
------------
          1
(1 row)

INSERT INTO seqvalues(id)
SELECT bdr.global_seq_nextval_test('dummy_seq2'::regclass, '530605914245317'::bigint)
FROM generate_series(0, (2 ^ 14)::bigint - 2);
SELECT last_value FROM dummy_seq2;
 last_value 
------------
      16383
(1 row)

SELECT count(id) FROM seqvalues;
 count 
-------
 32766
(1 row)

SELECT bdr.wait_slot_confirm_lsn(NULL,NULL);
 wait_slot_confirm_lsn 
-----------------------
 
(1 row)

\c regression
SELECT count(id) FROM seqvalues;
 count 
-------
 32766
(1 row)

